---
title: "単回帰と重回帰：それぞれの使い分け"
description: "単回帰分析と重回帰分析の包括的な比較。モデル選択、多重共線性、調整済みR二乗、予測変数の追加がモデルを改善する場合と悪化させる場合について解説します。"
date: "2026-02-20"
category: "検定比較"
tags:
  - 単回帰
  - 重回帰
  - 線形回帰
  - 多重共線性
  - モデル選択
  - 決定係数
  - VIF
  - 予測変数
---

## はじめに

線形回帰は統計分析の中心的な手法です。最もシンプルな形である**単回帰分析**では、1つの予測変数を用いてアウトカム（結果変数）のばらつきを説明します。**重回帰分析**はこの枚組みを2つ以上の予測変数に拡張し、複雑な関係のモデリングや交絡変数の統制を可能にします。

しかし、予測変数が多ければ良いモデルになるとは限りません。無関係な変数の追加はモデルの複雑さを増し、多重共線性を引き起こし、新しいデータに対する予測精度を低下させる可能性があります。本記事では、それぞれのアプローチをいつ使うべきか、モデルの比較方法、そしてよくある落とし穴の回避方法を解説します。

勉強時間と試験成績の関係をモデリングする場合でも、住宅価格の包括的なモデルを構築する場合でも、シンプルさと複雑さのトレードオフを理解することが不可欠です。実際の分析は[単回帰計算機](/calculators/simple-regression)や[重回帰計算機](/calculators/multiple-regression)でお試しください。