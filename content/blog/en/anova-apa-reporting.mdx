---
title: "How to Report ANOVA Results in APA Format (With Examples)"
description: "Learn how to report one-way ANOVA results in APA 7th edition format, including F statistics, degrees of freedom, partial eta squared, Tukey HSD post-hoc tests, and Welch's F for unequal variances."
date: "2026-02-18"
category: "APA Reporting"
tags: ["ANOVA", "APA format", "statistical reporting", "post-hoc test", "partial eta squared", "Tukey HSD"]
---

## Why Correct ANOVA Reporting Matters

Analysis of Variance (ANOVA) is one of the most widely used statistical methods in the social and behavioral sciences. Whenever you need to compare means across three or more groups, ANOVA is the standard approach. Yet reporting ANOVA results correctly in APA format trips up many researchers, from graduate students to experienced academics.

Unlike a t-test, ANOVA reporting involves two sets of degrees of freedom, a different effect size measure, and the critical step of post-hoc testing. Getting any of these wrong can trigger revision requests from reviewers or journal editors. This guide covers everything you need to report one-way ANOVA results in APA 7th edition format, with concrete numerical examples you can use as templates.

## The Basic APA Format for ANOVA Results

Every ANOVA result reported in APA style should include these essential components:

- **The F statistic**: italicized as *F*
- **Degrees of freedom**: between-groups df and within-groups df in parentheses, separated by a comma
- **The exact p value**: to three decimal places
- **Effect size**: partial eta squared (*η*²p) or eta squared (*η*²)

The general template looks like this:

> *F*(df_between, df_within) = X.XX, *p* = .XXX, *η*²p = .XX

Rounding conventions follow standard APA rules. The *F* statistic is rounded to two decimal places. The *p* value is reported to three decimal places. Values that cannot exceed 1 (such as *p* and *η*²p) omit the leading zero, so you write .013 rather than 0.013.

## Reporting a One-Way ANOVA: Step by Step

### Research Scenario

Imagine you are comparing test scores across three teaching methods: traditional lecture (n = 30), discussion-based learning (n = 30), and project-based learning (n = 30), for a total of 90 students.

### Descriptive Statistics

Always begin by presenting the descriptive statistics for each group.

| Teaching Method | n | *M* | *SD* |
|-----------------|---|------|------|
| Traditional lecture | 30 | 72.40 | 10.25 |
| Discussion-based | 30 | 78.93 | 9.87 |
| Project-based | 30 | 80.17 | 11.02 |

### Writing the Results

**Correct APA reporting example:**

> A one-way ANOVA revealed a statistically significant effect of teaching method on test scores, *F*(2, 87) = 4.52, *p* = .013, *η*²p = .09. This indicates that teaching method accounted for approximately 9% of the variance in test scores.

### Breaking Down the Components

| Component | Value | Explanation |
|-----------|-------|-------------|
| *F* | 4.52 | The F statistic, rounded to two decimal places |
| df | 2, 87 | Between-groups df (k - 1 = 3 - 1) and within-groups df (N - k = 90 - 3) |
| *p* | .013 | Exact p value with no leading zero |
| *η*²p | .09 | Partial eta squared, no leading zero |

### Non-Significant Result

> A one-way ANOVA indicated no statistically significant difference in test scores across teaching methods, *F*(2, 87) = 1.24, *p* = .295, *η*²p = .03.

Non-significant results follow the same format. Always include the effect size regardless of statistical significance.

## Interpreting Partial Eta Squared

Partial eta squared (*η*²p) is the most commonly reported effect size for ANOVA. Cohen (1988) proposed the following benchmarks:

| *η*²p | Interpretation |
|-------|----------------|
| .01 | Small effect |
| .06 | Medium effect |
| .14 | Large effect |

In the example above, *η*²p = .09 falls in the medium range. APA 7th edition requires that effect sizes accompany all inferential tests, so never report an *F* statistic without an effect size measure.

## Reporting Tukey HSD Post-Hoc Tests

A significant ANOVA result tells you that at least one group mean differs from the others, but it does not tell you which specific groups differ. To answer that question, you need a **post-hoc test**. Tukey's Honestly Significant Difference (HSD) is the most commonly used method.

### Post-Hoc Reporting Example

> Tukey HSD post-hoc comparisons indicated that students in the traditional lecture group (*M* = 72.40) scored significantly lower than those in the discussion-based group (*M* = 78.93), *p* = .038, *d* = 0.65, and those in the project-based group (*M* = 80.17), *p* = .011, *d* = 0.73. The difference between the discussion-based and project-based groups was not statistically significant, *p* = .874, *d* = 0.12.

### Post-Hoc Results Table

When comparisons are numerous, a table improves readability.

| Comparison | Mean Difference | *SE* | *p* | *d* |
|------------|----------------|------|------|------|
| Traditional vs Discussion | -6.53 | 2.68 | .038 | 0.65 |
| Traditional vs Project | -7.77 | 2.68 | .011 | 0.73 |
| Discussion vs Project | -1.24 | 2.68 | .874 | 0.12 |

Including Cohen's *d* for each pairwise comparison helps readers evaluate the practical significance of each difference.

## When Equal Variances Are Violated: Welch's F

Standard one-way ANOVA assumes that the variances across groups are equal (homogeneity of variances). When Levene's test indicates this assumption is violated, you should use **Welch's F test** instead.

### Reporting Levene's Test

> Levene's test indicated that the assumption of homogeneity of variances was violated, *F*(2, 87) = 4.18, *p* = .019.

### Reporting Welch's F

> Because the homogeneity of variances assumption was not met, a Welch's F test was conducted. Results indicated a statistically significant effect of teaching method on test scores, Welch's *F*(2, 56.34) = 4.87, *p* = .011, *η*²p = .10.

Notice that the denominator degrees of freedom in Welch's F are typically non-integer. Report them to two decimal places. When using Welch's F, the appropriate post-hoc test is **Games-Howell** rather than Tukey HSD, as it does not assume equal variances.

## Common Mistakes to Avoid

### Skipping Post-Hoc Tests

Reporting a significant ANOVA without specifying which groups differ is incomplete. Always follow up a significant omnibus *F* test with pairwise comparisons using an appropriate post-hoc method.

### Reversing the Degrees of Freedom

In *F*(2, 87), the first number is the between-groups (numerator) df and the second is the within-groups (denominator) df. Swapping these values fundamentally changes the meaning of the test. Double-check the order before finalizing your manuscript.

### Reporting p = .000

Statistical software sometimes displays p = .000, but this does not mean the probability is exactly zero. Always report this as *p* < .001.

### Using the Wrong Effect Size

Cohen's *d* is designed for two-group comparisons and is not appropriate as the overall effect size for ANOVA. Use **partial eta squared (*η*²p)** or **omega squared (*ω*²)** for the omnibus test. You may report Cohen's *d* for individual pairwise comparisons in post-hoc analyses.

### Ignoring the Equal Variance Assumption

Failing to test or report the homogeneity of variances assumption is a common oversight. If Levene's test is significant, switch to Welch's F and use Games-Howell for post-hoc comparisons. Mention this explicitly in your results section.

### Omitting Descriptive Statistics

Reporting only *F*, *p*, and *η*²p without group means and standard deviations leaves readers unable to interpret the direction and magnitude of group differences. Always include a descriptive statistics table or report *M* and *SD* inline.

## APA ANOVA Reporting Checklist

Before submitting your manuscript, verify that your ANOVA results include all of the following:

- Descriptive statistics (*M* and *SD*) for each group
- The *F* statistic rounded to two decimal places
- Degrees of freedom in the correct order (between, within)
- The exact *p* value (or *p* < .001 for very small values)
- Partial eta squared (*η*²p) as the effect size
- Post-hoc test results when the omnibus *F* is significant
- Welch's F and Games-Howell if equal variances are violated
- All statistical symbols (*F*, *p*, *η*²p, *M*, *SD*) in italics

## Using StatMate for APA-Formatted ANOVA Results

Formatting ANOVA results correctly becomes increasingly tedious when your study involves multiple comparisons and post-hoc tests. StatMate's ANOVA calculator handles the entire process automatically.

Enter your data or summary statistics, and StatMate computes the *F* statistic, degrees of freedom, exact *p* value, partial eta squared, and post-hoc comparisons with effect sizes. The results are output in APA 7th edition format, ready to paste directly into your manuscript.

By letting StatMate handle the formatting, you avoid common errors like reversed degrees of freedom, missing effect sizes, or incorrect decimal places, and you can focus your time on interpreting your findings and writing your discussion.

## Summary

Reporting ANOVA results in APA format requires more components than a simple t-test, but the underlying logic is the same: provide enough information for your reader to evaluate the statistical evidence. Include the **F statistic, both degrees of freedom, the exact p value, and partial eta squared**. When the omnibus test is significant, follow up with **post-hoc pairwise comparisons**. If the equal variance assumption is violated, use **Welch's F with Games-Howell post-hoc tests**. Use the examples and checklist in this guide as a reference whenever you write up your next ANOVA analysis.
